---
title: "Math 381 Project 2: Sentiment Analysis of Songs"
author: "Eunji Lee | Yuan Qu | Arnav Dubey"
date: "November 25, 2017"
output:
  html_document:
    df_print: paged
  html_notebook:
    theme: readable
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r warning=FALSE, message=FALSE}
rm(list=ls())
library(stringr)
library(markovchain)
library(SentimentAnalysis)
library(GGally)
```


```{r}
Clean_String <- function(string){
    # Lowercase
    temp <- tolower(string)
    #' Remove everything that is not a number or letter (may want to keep more 
    #' stuff in your actual analyses). 
    temp <- stringr::str_split(temp, "\n")[[1]]
    temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ")
    # Shrink down to just one white space
    temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
    temp <- trimws(temp)
    # Split it
    # 
    # Get rid of trailing "" if necessary
    indexes <- which(temp == "")
    if(length(indexes) > 0){
      temp <- temp[-indexes]
    } 
    return(temp)
}
```


```{r}
#' function to clean text
Clean_Text_Block <- function(text){
    if(length(text) <= 1){
        # Check to see if there is any text at all with another conditional
        if(length(text) == 0){
            cat("There was no text in this document! \n")
            to_return <- list(num_tokens = 0, unique_tokens = 0, text = "")
        }else{
            # If there is , and only one line of text then tokenize it
            clean_text <- Clean_String(text)
            num_tok <- length(clean_text)
            num_uniq <- length(unique(clean_text))
            to_return <- list(num_tokens = num_tok, unique_tokens = num_uniq, text = clean_text)
        }
    }else{
        # Get rid of blank lines
        indexes <- which(text == "")
        if(length(indexes) > 0){
            text <- text[-indexes]
        }  
        # Loop through the lines in the text and use the append() function to 
        clean_text <- Clean_String(text[1])
        for(i in 2:length(text)){
            # add them to a vector 
            clean_text <- append(clean_text,Clean_String(text[i]))
        }
        # Calculate the number of tokens and unique tokens and return them in a 
        # named list object.
        num_tok <- length(clean_text)
        num_uniq <- length(unique(clean_text))
        to_return <- list(num_tokens = num_tok, unique_tokens = num_uniq, text = clean_text)
    }
    return(to_return)
}
```

```{r}
get_clean_speech <- function(docs){
   list_clean_speech <- list()
   for (idx in 1:length(docs)){
      clean_speech <- Clean_Text_Block(docs[idx])
      list_clean_speech[idx] <- list(clean_speech)
   }
   return(list_clean_speech)
}
```


```{r}
# Analyze sentiment for each sentence of the song.
get_sentiment_scores <- function(list_input){
   list_sentiment <- list()
   for (idx in 1:length(list_input)){
      sentiment <- tryCatch(analyzeSentiment(list_input[[idx]]$text), 
                            error=function(e) NULL)
      list_sentiment[idx] <- na.omit(list(sentiment))
      print(idx)
   }  
   return(list_sentiment)
}
```


```{r}
# converts continuous variable (sentiment scores) to discrete variable.
make_discrete <- function(x) {
   
   if(x < 0) {
      sign <- -1 
   } else if(x > 0) {
      sign <- 1 
   } else {
      sign <- 0
   }
   
   y = abs(x)^{1/3} # scaling using power
   
   if(y > 0.5){     # because 0.125^{1/3} = 0.5, we want to capture more non-neutral sentiment.
      significance = 1
   } else{
      significance = 0
   }
   
   if(significance == 0){
      x <- 0
   } else {
      x <- sign
   }
}

# vectorizes the funciton
v_make_discrete <- Vectorize(make_discrete)

# coverts sentiments to discrete type
get_discrete_scores <- function(list_sentiment){
   list_dis_sentiments <- list()
   for(i in 1:length(list_sentiment)){
      list_dis_sentiments[[i]] <- v_make_discrete(na.omit(list_sentiment[[i]]$SentimentQDAP))
   }
   return(list_dis_sentiments)
}
```



```{r}
# uses markovchain package in R to calculate the matrix probabilites
get_markov_fits <- function(list_dis_sentiments){
   list_markov_fits <- list()
   for(i in 1:length(list_dis_sentiments)){
      mcFit <- markovchainFit(data = list_dis_sentiments[[i]], byrow = TRUE)
      list_markov_fits[[i]] <- mcFit$estimate@transitionMatrix
   }
   return(list_markov_fits)
}
```


```{r}
# uses markovchain package in R to calculate the matrix probabilites
get_sentiment_scores <- function(list_input){
   list_sentiment <- list()
   for (idx in 1:length(list_input)){
      sentiment <- tryCatch(analyzeSentiment(list_input[[idx]]$text), 
                            error=function(e) NULL)
      list_sentiment[idx] <- na.omit(list(sentiment))
      print(idx)
   }  
   return(list_sentiment)
}
```


## Ed Sheeran

```{r}
df_ed_sheeran <- read.csv(file="./data/songs_lyrics_list_Ed_Sheeran.csv", header=TRUE, sep=",")
head(df_ed_sheeran)
```

```{r}
docs_ed <- c(levels(df_ed_sheeran$Lyrics))
docs_ed[1]
```


```{r}

list_clean_speech_ed <-get_clean_speech(docs_ed)

list_clean_speech_ed[[3]]
```


```{r}
# analyzeSentiment(list_clean_speech[[82]]$text)$SentimentQDAP # check which songs don't work with the package.
# 
# remove songs that don't work with the SentimentAnalysis package.
list_input_ed <- list_clean_speech_ed[-c(15, 17, 24, 30, 38, 46, 49, 82)]


list_sentiment_ed <- get_sentiment_scores(list_input_ed)
# list_sentiment = list_sentiment[-which(sapply(list_sentiment, is.null))]
list_sentiment_ed[[15]]$SentimentQDAP
```

```{r}
capture.output(list_sentiment_ed, file = "./output/list_sentiment_ed.txt")
```


```{r}
list_dis_sentiments_ed <- get_discrete_scores(list_sentiment_ed)


list_dis_sentiments_ed[[3]]
```

```{r}
capture.output(list_dis_sentiments_ed, file = "./output/list_discrete_sentiments_ed.txt")
```

```{r}
list_markov_fits_ed <- get_markov_fits(list_dis_sentiments_ed)

list_markov_fits_ed[[69]] # corresponds to the song "Shape of You".
```


```{r}
capture.output(list_markov_fits_ed, file = "./output/list_markov_fits_ed.txt")
```

## Beyonce

```{r}
df_beyonce <- read.csv(file="./data/songs_lyrics_list_Beyonce.csv", header=TRUE, sep=",")
head(df_beyonce)
```

```{r}
docs_bey <- c(levels(df_beyonce$Lyrics))
docs_bey[1]
```

```{r}
list_clean_speech_bey <-get_clean_speech(docs_bey)

list_clean_speech_bey[[3]]
```

```{r}
# Analyze sentiment for each sentence of the song.
# remove songs that don't work with the SentimentAnalysis package.
list_input_bey <- list_clean_speech_bey[-c(7, 10, 11, 15, 33, 34, 37, 73, 74, 83, 99, 103, 106,
                                           107, 108, 117, 118, 119, 139, 143, 144, 149, 155)]
list_sentiment_bey <- get_sentiment_scores(list_input_bey)
-which(sapply(list_sentiment, is.null))
list_sentiment = list_sentiment[-which(sapply(list_sentiment, is.null))]
list_sentiment_bey[[3]]$SentimentQDAP
```


```{r}
list_dis_sentiments_bey <- get_discrete_scores(list_sentiment_bey)

list_dis_sentiments_bey[[3]]
```


```{r}
capture.output(list_dis_sentiments_bey, file = "./output/list_discrete_sentiments_bey.txt")
```


```{r}
list_markov_fits_bey <- get_markov_fits(list_dis_sentiments_bey)

list_markov_fits_bey[[69]] 
```


```{r}
capture.output(list_markov_fits_bey, file = "./output/list_markov_fits_bey.txt")
```


## Coldplay

```{r}
df_cold <- read.csv(file="./data/songs_lyrics_list_Coldplay.csv", header=TRUE, sep=",")
head(df_cold)
```


```{r}
docs_cold <- c(levels(df_cold$Lyrics))
docs_cold[1]
```


```{r}
list_clean_speech_cold <-get_clean_speech(docs_cold)

list_clean_speech_cold[[1]]
```


```{r}
# remove songs that don't work with the SentimentAnalysis package.
list_input_cold <- list_clean_speech_cold #[-c(24, 28, 32, 33, 39, 49, 57, 58, 61, 64, 68, 87, 88, 105, 
                                             # 113, 114, 115, 116, 125, 126, 128, 140, 141, 142, 145, 146)]
list_sentiment_cold <- get_sentiment_scores(list_input_cold)         
which(sapply(list_sentiment_cold, is.null))
list_sentiment_cold = list_sentiment_cold[-which(sapply(list_sentiment_cold, is.null))]
list_sentiment_cold[[1]]$SentimentQDAP
```


```{r}
list_dis_sentiments_cold <- get_discrete_scores(list_sentiment_cold)

list_dis_sentiments_cold[[3]]
```


```{r}
capture.output(list_dis_sentiments_cold, file = "./output/list_discrete_sentiments_cold.txt")
```


```{r}
list_markov_fits_cold <- get_markov_fits(list_dis_sentiments_cold)

list_markov_fits_cold[[69]] 
```


```{r}
capture.output(list_markov_fits_cold, file = "./output/list_markov_fits_cold.txt")
```


## Maroon 5

```{r}
df_mar <- read.csv(file="./data/songs_lyrics_list_Maroon 5.csv", header=TRUE, sep=",")
head(df_mar)
```


```{r}
docs_mar <- c(levels(df_mar$Lyrics))
docs_mar[1]
```


```{r}
list_clean_speech_mar <-get_clean_speech(docs_mar)

list_clean_speech_mar[[3]]
```


```{r}
# remove songs that don't work with the SentimentAnalysis package.
list_input_mar <- list_clean_speech_mar# [-c(2, 6, 12, 17, 30, 40, 44, 48, 49, 52, 
                                           # 56, 58, 59, 79, 87, 94, 103, 111, 116)]
list_sentiment_mar <- get_sentiment_scores(list_input_mar)         
which(sapply(list_sentiment_mar, is.null)) # uncomment to figure out which songs don't work with the package ie. throw an error
list_sentiment_mar = list_sentiment_mar[-which(sapply(list_sentiment_mar, is.null))]
list_sentiment_mar[[1]]
length(list_sentiment_mar)
```


```{r}
list_dis_sentiments_mar <- get_discrete_scores(list_sentiment_mar)

list_dis_sentiments_mar[[3]]
```


```{r}
capture.output(list_dis_sentiments_mar, file = "./output/list_discrete_sentiments_mar.txt")
```


```{r}
list_markov_fits_mar <- get_markov_fits(list_dis_sentiments_mar)

list_markov_fits_mar[[69]] 
```


```{r}
capture.output(list_markov_fits_mar, file = "./output/list_markov_fits_mar.txt")
```


## Bruno Mars

```{r}
df_bru <- read.csv(file="./data/songs_lyrics_list_Bruno Mars.csv", header=TRUE, sep=",")
head(df_bru)
```


```{r}
docs_bru <- c(levels(df_bru$Lyrics))
docs_bru[1]
```


```{r}
list_clean_speech_bru <-get_clean_speech(docs_bru)

list_clean_speech_bru[[3]]
```


```{r}
# remove songs that don't work with the SentimentAnalysis package.
list_input_bru <- list_clean_speech_bru # [-c(4, 5, 6, 8, 9, 13, 34)]
list_sentiment_bru <- get_sentiment_scores(list_input_bru)         
which(sapply(list_sentiment_bru, is.null))
list_sentiment_bru = list_sentiment_bru[-which(sapply(list_sentiment_bru, is.null))]
list_sentiment_bru[[3]]$SentimentQDAP
length(list_sentiment_bru)
```


```{r}
list_dis_sentiments_bru <- get_discrete_scores(list_sentiment_bru)

list_dis_sentiments_bru[[3]]
```


```{r}
capture.output(list_dis_sentiments_bru, file = "./output/list_discrete_sentiments_bru.txt")
```


```{r}
list_markov_fits_bru <- get_markov_fits(list_dis_sentiments_bru)

list_markov_fits_bru[[1]]
```

```{r}
capture.output(list_markov_fits_bru, file = "./output/list_markov_fits_bru.txt")
```